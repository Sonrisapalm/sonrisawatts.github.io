<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>About - Emotion Encoded</title>
  
  <!-- Google Fonts: Poppins -->
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap" rel="stylesheet" />
  
  <link rel="stylesheet" href="style.css" />
</head>
<body class="about-body">

 <nav>
  <a href="index.html">Home</a>
  <a href="about.html">About</a>
  <a href="articles.html">Articles</a>  <!-- make sure this is here -->
  <a href="contact.html">Contact</a>
</nav>

  <header class="about-header">
    <h1>About Emotion Encoded</h1>
    <p>Understanding emotional reasoning and psychological bias in AI interaction.</p>
  </header>

  <main class="about-main">
    <section>
      <h2>Our Mission</h2>
      <p>
        Emotion Encoded explores the intersection of psychology and artificial intelligence,
        focusing on how emotional reasoning, cultural contexts, and biases influence human trust in AI systems.
        We aim to foster greater transparency, AI Trust Governance, and inclusive technologies that respect diverse human experiences and values.
      </p>
    </section>

    <section>
      <h2>Founder</h2>
      <p>
        Sonrisa Watts, 24-year old who recently graduated with a BSc psychology degree. Recently developed a profound interest in Experimental/Research Psychology, mainly in the intersection of Artificial Intelligence and Psychology. Concerned about how human perceive and trust AI,  she founded Emotion Encoded to bridge the gap between psychological science and AI development. Through her work, she promotes interdisciplinary collaboration to build AI systems that are trustworthy and empathetic.
      </p>
    </section>

    <section>
      <h2>What We Do</h2>
      <p>
        As founder, I conduct research, facilitate dialogues and publish the findings, motivated by my interest in developing tools that investigate cognitive biases and emotional reasoning in AI adoption. By partnering with professionals in law, medicine, and policy, we strive to create frameworks that support transparent, accountable, and fair AI integration in society.
      </p>
    </section>
  </main>
  
<section class="full-width-bg" id="about-research">
  <div class="container" style="max-width: 800px; margin: 0 auto; padding: 2em; color: white;">
    <h2>Why My Research is a Goldmine</h2>

    <p>While others focus on the hypothetical technical solutions to AI's grandest challenges, I am focused on the human-centered foundations of the problem.</p>

    <h3>Trust</h3>
    <p>
      I investigate why people trust or don't trust AI. Building a safe, aligned AI is impossible if no one trusts it. My work is about building the necessary societal and psychological preconditions for AI adoption. I'm investigating the cognitive biases and psychological persepctives of humans that can affect the integration, adoption and resistance of Artificial Intelligence.
    </p>

    <h3>Transparency</h3>
    <p>
      My central idea is that Explainable AI is a "consumer manual for a broken tool." It is impossible to align a superintelligent system if we don't understand how it thinks. Transparency is the only way for me to audit, correct, and ultimately, align a system's behavior with human values.
    </p>

    <h3>Resistance</h3>
    <p>
      I study why people resist AI. This isn't just a negative reaction; it's a crucial feedback mechanism. Resistance is a signal that the AI's current design or behavior is misaligned with human values, needs, or ethics. By understanding resistance, I am identifying where the alignment problem is already happening on a smaller scale.
    </p>
  </div>
</section>

  <footer>
    © 2025 Emotion Encoded — All rights reserved.
  </footer>

</body>
</html>
