<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AI Advisor vs AI Therapist — Emotion Encoded</title>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="style.css" />
</head>
<body>

  <nav>
    <a href="index.html">Home</a>
    <a href="articles.html" class="active">Articles</a>
    <a href="about.html">About</a>
    <a href="contact.html">Contact</a>
  </nav>

  <header>
    <h1>Who Would You Trust More: An AI Advisor or an AI Therapist?</h1>
    <p>Insights from Emotion Encoded community responses.</p>
  </header>

  <main>
    <article>
      <!-- Top image (optional) -->
      <img src="images/article1.jpg" alt="AI Advisor vs AI Therapist" class="article-img" />

      <p><strong>“Who would you trust more: An AI Advisor or an AI Therapist?”</strong></p>
      <p>The answers were telling.</p>

      <blockquote>“Financial advisor is a little too private for me.”</blockquote>
      <blockquote>“I prefer a human to deal with my money.”</blockquote>
      <blockquote>“Therapist errors are less likely to be lethal.”</blockquote>
      <blockquote>“Although both should be private, an AI therapist can draw on a large resource and apply it to challenges I may be experiencing, whereas finances are more personal.”</blockquote>
      <blockquote>“Therapist work may involve actual human feelings and rational thinking, while financial advice is based on numbers and their interpretation.”</blockquote>
      <blockquote>“A therapist needs a certain level of emotional intelligence that AI has not developed.”</blockquote>
      <blockquote>“Finance is numbers. I can sort out my own feelings.”</blockquote>
      <blockquote>“Therapist has a lot more nuances and human components that robots can’t completely understand.”</blockquote>

      <h2>What This Reveals</h2>
      <p>
        These responses highlight something bigger than just preferences—they expose how people weigh
        risk and trust differently across domains.
      </p>

      <p>
        For some, money feels too intimate to hand over to a machine. To them, a wrong move from an
        AI advisor could mean real, irreversible losses. On the other hand, therapy was sometimes
        seen as safer for experimentation: an AI can pull from vast psychological resources, and if
        it’s ‘wrong’, the consequences may not feel as severe as financial errors.
      </p>

      <p>
        Others saw the opposite. Therapy requires empathy, nuance, and human warmth—qualities AI
        cannot truly replicate. Financial advice, being grounded in data and numbers, was perceived
        as something AI should be better at.
      </p>

      <p>
        This tension shows that trust isn’t automatic—it’s situational. People ask:
        <em>What’s at stake? What can go wrong? What do I lose if the AI makes a mistake?</em>
      </p>
    </article>
  </main>

  <footer>
    © 2025 Emotion Encoded — All rights reserved.
  </footer>

</body>
</html>
