<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Exploring AI in Medicine — Emotion Encoded</title>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css">
</head>
<body>

  <nav>
    <a href="index.html">Home</a>
    <a href="articles.html" class="active">Articles</a>
    <a href="about.html">About</a>
    <a href="contact.html">Contact</a>
  </nav>

  <header>
    <!-- ✅ Image updated with smaller sizing -->
    <img src="images/article10.jpg" 
         alt="Parents, Teachers, and AI in the Classroom" 
         style="max-width:85%; height:auto; display:block; margin:1em auto; border-radius:12px;">

    <h1>Exploring AI in Medicine: Perspectives from a Young General Practitioner</h1>
    <p>Insights from Emotion Encoded’s research initiative with Sonrisa Watts.</p>
  </header>

  <main class="article-content">
    <p>Artificial Intelligence (AI) is transforming industries worldwide, but its integration into medicine raises important questions about trust, bias, and human-centered care. Discussions about AI's role in diagnostic tools, predictive analytics, and medical imaging highlight both promise and concern. As part of the Emotion Encoded research initiative, Sonrisa Watts, founder, spoke with a young general practitioner to understand how healthcare professionals perceive AI’s role in patient care.</p>
    <p>**To ensure the candidness of our interviewees and to protect their professional privacy on this sensitive topic, all participants were granted anonymity**</p>
    <h2>Balancing Helpfulness and Caution</h2>
    <p>When asked about using AI in medicine, the doctor reflected a nuanced view:</p>
    <blockquote>
      “I’d say AI in medicine feels like both helpful and a little scary, depending on how it’s used. But for the most part it can be very helpful because it can be used to improve accuracy, speed up diagnoses, and supports doctors in making better decisions for patient care.”
    </blockquote>
    <p>This perspective highlights a key tension in AI adoption: while technology promises efficiency and enhanced diagnostic capabilities, it also introduces potential risks if applied without careful oversight. The doctor emphasized AI’s role as a supportive tool, not a replacement for professional judgment.</p>

    <h2>Human Judgment Remains Central</h2>
    <p>We asked whether the doctor would trust AI recommendations over their own clinical intuition. Her response was clear:</p>
    <blockquote>
      “The final trust would definitely rest on my medical training, evidence-based practice, and clinical intuition. However, AI can be a valuable prompt to double-check or consider something that I may have overlooked.”
    </blockquote>
    <p>AI can serve as a secondary layer of support, but the foundation of medical decision-making remains firmly rooted in human expertise and experience.</p>

    <h2>Preference for the “Old Way”</h2>
    <p>Many patients and healthcare professionals are drawn to traditional approaches to care. When asked if doctors and patients might prefer the “old way” over AI, the doctor explained:</p>
    <blockquote>
      “Yes I do think most doctors and patients would prefer the ‘old way’ since it offers a more human connection, a stronger sense of trust, and a personal touch in care.”
    </blockquote>
    <p>This underscores the emotional and relational aspects of medicine—elements that technology cannot fully replicate. Trust, empathy, and human interaction are vital to the patient experience.</p>

    <h2>Awareness of AI Bias and Limitations</h2>
    <p>The doctor also acknowledged AI’s potential to make errors or perpetuate bias:</p>
    <blockquote>
      “Yes, AI in healthcare can certainly make errors or show bias. It relies on the data it’s trained on, so gaps or unequal representation in that data can lead to inaccurate or unfair recommendations.”
    </blockquote>
    <p>This highlights the ethical responsibility of integrating AI in healthcare. Systems must be carefully monitored, and human oversight is essential to ensure equitable and accurate outcomes.</p>

    <h2>Patients, Comfort, and the Human Side of Medicine</h2>
    <p>Finally, we explored patient perspectives and AI’s ability to understand the human side of care. The doctor observed:</p>
    <blockquote>
      “I think that most patients may feel uneasy if AI was significantly involved in their diagnosis or treatment, especially if it replaces face-to-face interaction with a physician. Trust often comes from empathy, reassurance, and human connection, which AI can’t fully replicate.”
    </blockquote>
    <p>Regarding AI’s capacity to comprehend human emotions and cultural context:</p>
    <blockquote>
      “I don’t think that AI can truly understand the human side of medicine such as emotions, concerns, cultural context, or personal values. It’s best used as a tool for support, but definitely not to replace the human care that patients heavily rely on.”
    </blockquote>
    <p>The insights here make it clear: AI can enhance healthcare delivery, but it cannot replace the empathy, judgment, and nuanced understanding that define human care.</p>

    <h2>Conclusion</h2>
    <p>This conversation with a young general practitioner reflects a thoughtful approach to AI in medicine: one that balances optimism with caution, leverages technology for support, and prioritizes human-centered care. As AI continues to evolve, research initiatives like Emotion Encoded are crucial for exploring how emotional reasoning, trust, and cultural context shape the adoption of technology in professional settings.</p>
    <p>AI may help doctors make faster, more accurate decisions, but the heart of medicine, which is empathy, understanding, and human connection remains irreplaceable.</p>
  </main>

  <footer>
    © 2025 Emotion Encoded — All rights reserved.
  </footer>

</body>
</html>
