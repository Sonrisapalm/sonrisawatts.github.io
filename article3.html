<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Article Three — Emotion Encoded</title>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="style.css" />
</head>
<body>

  <nav>
    <a href="index.html">Home</a>
    <a href="articles.html" class="active">Articles</a>
    <a href="about.html">About</a>
    <a href="contact.html">Contact</a>
  </nav>

  <header>
    <h1>AI Trust Insights</h1>
    <p>Results from the Emotion Encoded survey on AI trust.</p>
  </header>

  <main>
    <section id="articles">
      <article>
        <img src="images/articlethree.jpg" alt="Article Three Illustration" class="article3-img" />

        <p>
          Emotion Encoded asked "What would you need to know about an AI tool in order to trust it?"<br/>
          Some of the responses that the majority of participants chose were:
        </p>

        <ul>
          <li>Details about how the system was developed</li>
          <li>Information about how my personal data is stored and used</li>
          <li>Information about the data it was trained on</li>
          <li>Whether it has been tested for bias</li>
          <li>How often it makes mistakes</li>
          <li>Whether a human was involved in reviewing and approving its output</li>
        </ul>

        <p>
          What can we understand from this? These insights show that trust in AI must be earned through transparency, ethical safeguards, and clear communication. Many companies safeguard their intentions with people's data, as well as the details about their AI development.
        </p>

        <p>
          As AI continues to transform industries, we must build systems that not only deliver technical performance but also respect human values.
        </p>
      </article>
    </section>
  </main>

  <footer>
    © 2025 Emotion Encoded — All rights reserved.
  </footer>

</body>
</html>
