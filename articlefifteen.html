<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>When AI Disagrees with Your Doctor: Who Do You Trust?</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;500;700&display=swap" rel="stylesheet" />
    <style>
        body {
            font-family: 'Poppins', sans-serif;
            background-image: url('images/websitebackground.jpg');
            background-size: cover;
            background-repeat: no-repeat;
            background-position: center;
            background-attachment: fixed;
            color: #f0f0f0;
            line-height: 1.7;
            overflow-x: hidden;
        }
        .text-shadow-md {
            text-shadow: 1px 1px 3px rgba(0, 0, 0, 0.6);
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-100">

    <!-- Navigation -->
    <nav class="sticky top-0 z-50 bg-gray-900/90 py-4 shadow-lg text-center">
        <div class="flex flex-wrap justify-center gap-x-6 gap-y-2 text-base md:text-lg font-medium max-w-7xl mx-auto px-4">
            <a href="index.html" class="text-white hover:text-orange-400 transition-colors duration-200">Home</a>
            <a href="about.html" class="text-white hover:text-orange-400 transition-colors duration-200">About</a>
            <a href="AI-Perception-Briefs.html" class="text-white hover:text-orange-400 transition-colors duration-200">Research Findings Articles</a>
            <a href="contact.html" class="text-white hover:text-orange-400 transition-colors duration-200">Contact</a>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="container mx-auto p-4 md:p-8 space-y-12 max-w-4xl">
        <section class="bg-gray-800/50 p-6 md:p-10 rounded-3xl shadow-lg mt-8">
            <img src="images/article15.jpg" alt="A doctor and a patient discussing an AI-generated diagnosis" class="w-full h-auto rounded-2xl mb-8 shadow-md" />
            <h2 class="text-3xl md:text-4xl font-bold mb-4 text-white text-center leading-tight">
                When AI Disagrees with Your Doctor: Who Do You Trust?
            </h2>
            <p class="text-lg leading-relaxed text-gray-200 mt-6">
                Emotion Encoded asked 41 participants a simple but unsettling question: “What would you do if a hospital AI tool recommended a treatment that was different from your doctor’s advice?” The answers revealed something deeper than statistics. They revealed a struggle with trust.
            </p>

            <ul class="list-disc list-inside space-y-2 text-lg leading-relaxed text-gray-200 ml-4 mt-4">
                <li>**41.5%** said they would discuss both options before deciding.</li>
                <li>**31.7%** said they would seek a second opinion.</li>
                <li>**17.1%** said they would follow only the doctor’s advice.</li>
                <li>**9.8%** said they would combine both suggestions.</li>
            </ul>

            <p class="text-lg leading-relaxed text-gray-200 mt-4">
                At first glance, these numbers look like preferences. But beneath them is a shift in how people think about expertise, risk, and authority. For centuries, the doctor’s word was final. Yet here, fewer than 1 in 5 participants would accept their doctor’s advice without hesitation when AI presents a different path. Instead, most people wanted conversation, validation, or further proof. Some even considered blending human and machine recommendations into a single approach. This suggests that AI is not simply a tool in healthcare. It is a new actor in the decision-making process, one that patients cannot ignore.
            </p>

            <h3 class="text-2xl font-bold mt-8 mb-2 leading-tight">What does this mean for the future?</h3>
            <p class="text-lg leading-relaxed text-gray-200">
                It means trust is no longer binary. It is not about either trusting your doctor or the AI. Instead, trust becomes a negotiation between human expertise, machine precision, and the patient’s own intuition.
            </p>
            <p class="text-lg leading-relaxed text-gray-200 mt-4">
                In high-stakes fields like medicine, this negotiation could reshape everything. Patients may demand more transparency. Doctors may need to defend their reasoning against algorithms. AI developers may be forced to design systems that explain their choices, not just output them.
            </p>
            <p class="text-lg leading-relaxed text-gray-200 mt-4">
                At Emotion Encoded, we see this not as a valuable insight. People are telling us: we do not blindly trust anymore. But what about trusting solely clinical intuition? This sets the blueprint for how AI must evolve if it is to coexist with human judgment.
            </p>
            <p class="text-lg leading-relaxed text-gray-200 mt-4">
                Because the real question is not just “Doctor or AI?” The real question is: how do we create a world where patients feel secure in choosing either, or both?
            </p>
        </section>
    </main>

    <!-- Footer -->
    <footer class="bg-gray-900/90 text-center py-6 mt-12 text-gray-400">
        © 2025 Emotion Encoded — All rights reserved.
    </footer>

</body>
</html>
