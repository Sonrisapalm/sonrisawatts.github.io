<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Encoded: A Tech Professional’s Verdict on AI</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0d1117;
            color: #e6edf3;
        }
        .text-gradient {
            background-image: linear-gradient(to right, #f87171, #fbbf24);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
    </style>
</head>
<body class="p-4 md:p-8">

    <!-- Header -->
    <header class="text-center py-16">
        <h1 class="text-4xl md:text-6xl font-extrabold mb-4 leading-tight text-gradient">A Tech Professional’s Verdict on AI in High-Stakes Fields</h1>
        <p class="text-lg md:text-xl text-gray-300 max-w-3xl mx-auto">
            Interview with Mr. Enoete Inanga
        </p>
    </header>

    <main class="max-w-4xl mx-auto">
        <!-- Article Image -->
        <div class="mb-8">
            <img src="images/article19.jpg" alt="A tech professional discusses AI in high-stakes fields" class="w-full h-auto rounded-2xl shadow-lg" />
        </div>

        <section class="mb-8 text-gray-300 text-lg">
            <p>
                Artificial intelligence is no longer a distant concept. It is shaping decisions in medicine, law, and finance with real consequences for human lives. To understand how professionals in technology view these risks and responsibilities, Emotion Encoded interviewed Mr. Enoete Inanga, a technology professional with sharp insight into the promises and pitfalls of AI. His responses reveal the fears, tensions, and pragmatic concerns shaping the future of human-AI collaboration.
            </p>
        </section>

        <!-- Status Quo Bias Section -->
        <section class="mb-12">
            <h2 class="text-3xl md:text-4xl font-bold text-center mb-6">Status Quo Bias: Why Organisations Resist Change</h2>
            <div class="bg-gray-800/50 rounded-3xl p-6 shadow-lg">
                <p class="text-gray-300 mb-4">
                    When asked why organisations still cling to their old systems, Mr. Inanga pointed to fear as the driving force.
                </p>
                <blockquote class="border-l-4 border-cyan-500 pl-4 italic text-gray-400">
                    “The fear of having to learn something new. Adapting new tech and methods require a change in company culture, habits, etc. This can be really scary for persons, even for some who are tech savvy.”
                </blockquote>
                <p class="text-gray-300 mt-4">
                    Resistance is not just about technical debt or messy data. It is about the human difficulty of leaving behind the familiar.
                </p>
            </div>
        </section>

        <!-- Algorithm Aversion Section -->
        <section class="mb-12">
            <h2 class="text-3xl md:text-4xl font-bold text-center mb-6">Algorithm Aversion: Who Gets Blamed?</h2>
            <div class="bg-gray-800/50 rounded-3xl p-6 shadow-lg">
                <p class="text-gray-300 mb-4">
                    What happens when an AI makes a harmful mistake in a hospital or courtroom? According to Mr. Inanga, blame does not fall on the system alone.
                </p>
                <blockquote class="border-l-4 border-cyan-500 pl-4 italic text-gray-400">
                    “The person who gets blamed is the person who chose to put 100% faith in a system that had NO guardrails to ensure the validity of the data. The fear of liability does play a very HIGH influence in the rejection of AI and tech. If AI can mess up with the simplest of situations, there is no telling the consequences of messing up when the stakes are higher.”
                </blockquote>
                <p class="text-gray-300 mt-4">
                    Fear of liability, he argues, is one of the biggest barriers to adoption.
                </p>
            </div>
        </section>

        <!-- Automation Bias Section -->
        <section class="mb-12">
            <h2 class="text-3xl md:text-4xl font-bold text-center mb-6">Automation Bias: Preventing Blind Reliance</h2>
            <div class="bg-gray-800/50 rounded-3xl p-6 shadow-lg">
                <p class="text-gray-300 mb-4">
                    How can professionals avoid over-relying on AI tools? Mr. Inanga proposed a striking solution.
                </p>
                <blockquote class="border-l-4 border-cyan-500 pl-4 italic text-gray-400">
                    “Hmm. I think it’s quite simple. Before committing to any document, solution, platform, have AI show similar projects, similar finished products that resulted in mistakes made with dire consequences just because the guard rails were not put in place. It’s almost the same as scaring teens into abstinence by showing them pictures of body parts infected with sexually transmitted infections.”
                </blockquote>
                <p class="text-gray-300 mt-4">
                    In other words, show the risks vividly so professionals never forget the cost of blind trust.
                </p>
            </div>
        </section>

        <!-- Illusion of Explainability Section -->
        <section class="mb-12">
            <h2 class="text-3xl md:text-4xl font-bold text-center mb-6">Illusion of Explainability: Simpler or Smarter?</h2>
            <div class="bg-gray-800/50 rounded-3xl p-6 shadow-lg">
                <p class="text-gray-300 mb-4">
                    When given the choice between a black-box model and a simpler, transparent one, his answer was clear.
                </p>
                <blockquote class="border-l-4 border-cyan-500 pl-4 italic text-gray-400">
                    “Simpler is better. Once you know for sure how the food is made, what ingredients went into it, then troubleshooting becomes a lot easier. Being able to tinker and tamper becomes easier too.”
                </blockquote>
                <p class="text-gray-300 mt-4">
                    Transparency, he suggests, outweighs complexity when human oversight is at stake.
                </p>
            </div>
        </section>

        <!-- Algorithms Codifying Injustice Section -->
        <section class="mb-12">
            <h2 class="text-3xl md:text-4xl font-bold text-center mb-6">Algorithms Codifying Injustice: Fix or Govern?</h2>
            <div class="bg-gray-800/50 rounded-3xl p-6 shadow-lg">
                <p class="text-gray-300 mb-4">
                    Bias in training data is one of the greatest threats to fairness in AI. Mr. Inanga emphasized that technical fixes are not enough.
                </p>
                <blockquote class="border-l-4 border-cyan-500 pl-4 italic text-gray-400">
                    “For sure governance and community review. Us humans are supposed to be the guardians of the last frontier. Overreliance on technical fixes again places the control and trust in the machines, which makes NO sense, seeing that’s why we ended up ‘here’ in the first place!!”
                </blockquote>
                <p class="text-gray-300 mt-4">
                    To him, the solution lies in human responsibility, not algorithmic quick fixes.
                </p>
            </div>
        </section>

        <!-- Personal Verdict Section -->
        <section class="mb-12">
            <h2 class="text-3xl md:text-4xl font-bold text-center mb-6">Personal Verdict: Where Would You Trust AI First?</h2>
            <div class="bg-gray-800/50 rounded-3xl p-6 shadow-lg">
                <p class="text-gray-300 mb-4">
                    Finally, he offered a personal view on where AI belongs today.
                </p>
                <blockquote class="border-l-4 border-cyan-500 pl-4 italic text-gray-400">
                    “I’ll trust AI first in Finance mainly because this is a numbers game and data is hardly ever subjective when it comes to finance. At the end of the day, it’s either you have the money or you dont!! ☺”
                </blockquote>
                <p class="text-gray-300 mt-4">
                    His perspective highlights a broader reality: some fields are inherently more suited for AI, while others demand greater caution.
                </p>
            </div>
        </section>

        <section class="mb-12 text-gray-300 text-lg">
            <p>
                Mr. Inanga’s insights cut through technical jargon to expose the raw human challenges of AI adoption. His answers underline a central theme of Emotion Encoded: the future of AI will not be shaped by algorithms alone, but by the people who choose when to trust them, when to question them, and when to push back.
            </p>
        </section>

        <!-- Image References / Footnotes Section -->
        <footer class="text-sm text-gray-500 mt-8 border-t border-gray-700 pt-4">
            <h3 class="text-lg font-bold mb-2 text-white">Footnotes</h3>
            <ol>
                <li>Polarize Poker. (2024, February 6). GTO in Poker: The Holy Grail of Great Play [Image]. Polarize Poker. Retrieved from https://polarize.poker/en/news/gto-no-poker-o-santo-graal-do-jogo-otimo/</li>
                <li>Freepik. (n.d.). Artificial intelligence image: cyborg gold color with electronic brain neural network [Image]. Freepik. Retrieved from https://www.freepik.com/premium-photo/artificial-intelligence-image-cyborg-gold-color-with-electronic-brain-neural-network-trained-using-virtual-hud-interface-machine-learning-technology-concept-scifi-cybernetic-robot-with-ai_37082107.htm</li>
            </ol>
        </footer>
        
        <!-- Back to Home Button -->
        <div class="text-center my-8">
            <a href="index.html" class="inline-block px-8 py-3 bg-gradient-to-r from-cyan-500 to-blue-500 text-white font-bold rounded-full shadow-lg transition-transform transform hover:scale-105 hover:shadow-xl">
                Back to Home
            </a>
        </div>
    </main>

    <!-- Footer -->
    <footer class="text-center text-gray-400 text-sm mt-16 py-8 border-t border-gray-700">
        &copy; 2024 Emotion Encoded. All rights reserved.
    </footer>

</body>
</html>
