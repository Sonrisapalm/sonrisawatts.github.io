<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Interview with Dr. Bichara Sahely: Trust, Bias, and the Emotional Compass in AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;500;700&display=swap" rel="stylesheet" />
    <style>
        body {
            font-family: 'Poppins', sans-serif;
            background-image: url('images/websitebackground.jpg');
            background-size: cover;
            background-repeat: no-repeat;
            background-position: center;
            background-attachment: fixed;
            color: #f0f0f0;
            line-height: 1.7;
            overflow-x: hidden;
        }
        .text-shadow-md {
            text-shadow: 1px 1px 3px rgba(0, 0, 0, 0.6);
        }
        blockquote {
            border-left: 4px solid #f97316;
            padding-left: 1.5rem;
            margin: 1.5rem 0;
            font-style: italic;
            /* Using a slightly darker, more opaque background for blockquotes */
            background-color: rgba(31, 41, 55, 0.7); /* bg-gray-800 with transparency */
            border-radius: 0.75rem;
            padding: 1.5rem;
        }
        blockquote p {
            font-style: normal;
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-100">

    <header class="relative w-full overflow-hidden min-h-[40vh] flex items-center justify-center pt-24 pb-8 px-4 bg-gray-900/80">
        <div class="relative z-10 text-center flex flex-col items-center max-w-7xl mx-auto">
            <h1 class="text-3xl md:text-5xl font-extrabold text-white mb-2 tracking-wide text-shadow-md">
                Emotion Encoded
            </h1>
            <p class="text-lg md:text-xl font-light max-w-3xl mx-auto text-shadow-md">
                By Sonrisa Watts: Exploring the intersection of psychology and AI to build trust and transparency.
            </p>
        </div>
    </header>

    <nav class="sticky top-0 z-50 bg-gray-900/90 py-4 shadow-lg text-center">
        <div class="flex flex-wrap justify-center gap-x-6 gap-y-2 text-base md:text-lg font-medium max-w-7xl mx-auto px-4">
            <a href="index.html" class="text-white hover:text-orange-400 transition-colors duration-200">Home</a>
            <a href="about.html" class="text-white hover:text-orange-400 transition-colors duration-200">About</a>
            <a href="AI-Perception-Briefs.html" class="text-white hover:text-orange-400 transition-colors duration-200">Research Findings Articles</a>
            <a href="contact.html" class="text-white hover:text-orange-400 transition-colors duration-200">Contact</a>
        </div>
    </nav>
    
    <main class="container mx-auto p-4 md:p-8 space-y-8 max-w-4xl">
        
        <div class="bg-gray-900/80 p-6 md:p-10 rounded-2xl shadow-2xl border border-gray-700/50">
            
            <section class="text-center mb-10">
                <h1 class="text-3xl md:text-4xl font-bold mb-4">
                    Interview with Dr. Bichara Sahely: Trust, Bias, and the Emotional Compass in AI
                </h1>
                <img src="images/article12.jpeg" alt="Dr. Bichara Sahely being interviewed" class="w-full h-auto rounded-3xl shadow-xl mb-6" />
                <p class="text-gray-400 text-sm">
                    Published on September 13, 2025
                </p>
                <p class="text-lg mt-6 leading-relaxed text-gray-200">
                    At Emotion Encoded, we ask not just how artificial intelligence works, but how people feel about it. Instinct, intuition, and lived experience often shape the way we approach new technologies. Few understand this better than Dr. Bichara Sahely, Consultant Physician in Internal Medicine, who generously shared his perspective on the promises and pitfalls of AI in medicine.
                    <br /><br />
                    Our conversation focused on four themes central to human-AI trust: status quo bias, automation bias, the illusion of explainability, and the risk of algorithms codifying injustice.
                </p>
            </section>

            <section class="prose prose-invert lg:prose-xl mx-auto text-gray-200">
                
                <h2 class="text-2xl md:text-3xl font-semibold mt-8 mb-4">
                    Status Quo Bias: Medicine Meets Change
                </h2>
                <p>
                    Doctors are trained to trust their judgment and long-established practices. When asked if this creates hesitation around adopting AI, Dr. Sahely acknowledged the tension but also pointed to the opportunities:
                </p>
                <blockquote>
                    <p>
                        “I cannot speak for other physicians, but I can see the value of using AI to do literature review, collate best practice guidelines, and to personalize treatment as best as is possible for a particular patient, given the limitations in human and medical resource availability. The more we use AI capabilities, the better we can partner its output with our own judgments and lived experiences to co-evolve a trustworthy partnership as a tool that best serves as an extension of our cognitive and caring abilities.”
                    </p>
                </blockquote>
                <p>
                    For him, AI is not a threat to clinical autonomy. It is a chance to extend human care, provided it is paired with the wisdom of experience.
                </p>

                <h2 class="text-2xl md:text-3xl font-semibold mt-8 mb-4">
                    Automation Bias: The Danger of Over-Trust
                </h2>
                <p>
                    AI outputs can look precise, which tempts professionals to lean too heavily on them. Dr. Sahely warns of the risks:
                </p>
                <blockquote>
                    <p>
                        “Yes, we can overcompensate for our insufficiencies by following blindly their outputs without grounding in lived experiences. Therefore, we must be vigilant curators and ultimately responsible for and accountable in the most transparent manner the advice we give to our patients, based on our AI-augmented answers.”
                    </p>
                </blockquote>
                <p>
                    He describes instincts and intuition, what he calls our “emotional GPS,” as an evolutionary safeguard. If AI aligns with this compass, trust can grow. If it does not, clinicians must resist the pull of blind deference. 
                </p>

                <h2 class="text-2xl md:text-3xl font-semibold mt-8 mb-4">
                    Illusion of Explainability: When Clarity Misleads
                </h2>
                <p>
                    AI often presents outputs in neat numbers or simplified explanations. Does this create a false confidence? Dr. Sahely sees nuance:
                </p>
                <blockquote>
                    <p>
                        “As the saying goes, trust but verify. Explainability is not an illusion but a perspective from the corpus of knowledge collated in the training data from journals and guidelines. This should create a true sense of confidence if it resonates with our clinical instincts and intuitions which are not prone to cultural and cognitive capture and hijack.”
                    </p>
                </blockquote>
                <p>
                    For him, AI explanations are not inherently deceptive. They must be tested against the clinician’s own knowledge and emotional compass to avoid false security.
                </p>

                <h2 class="text-2xl md:text-3xl font-semibold mt-8 mb-4">
                    Algorithms Codifying Injustice: Bias in Disguise
                </h2>
                <p>
                    Finally, we asked about AI repeating biases already present in medical records. Could doctors catch this, or does trust in the system make it harder? Dr. Sahely’s answer was strikingly candid:
                </p>
                <blockquote>
                    <p>
                        “We do not know what we do not know, and like all processes in life, there are blind spots through and through in our worldviews and also in the collective knowledge commons. So ultimately it would be our instincts and intuitions which would be our emotional compass/GPS to help us navigate successfully in the terrain of illness and diseases.”
                    </p>
                </blockquote>
                <p>
                    He cautions that blind trust, whether in our own judgments or in AI systems, can lead to harm. Instead, he emphasizes cultivating a quieter, deeper trust:
                </p>
                <blockquote>
                    <p>
                        “If we so choose to quiet the mind, open the heart, and allow the natural intelligence of love for ourselves, each other, and the planet move us in all that we think, feel and do each day.”
                    </p>
                </blockquote>

                <h2 class="text-2xl md:text-3xl font-semibold mt-8 mb-4">
                    Closing Reflections
                </h2>
                <p>
                    Dr. Sahely’s insights remind us that technology alone cannot define the future of medicine. Trust in AI must be balanced by trust in ourselves, our instincts, our intuition, and our responsibility to patients.
                    In his words, the path forward is not blind adoption or blind rejection. It is a process of co-evolution between human and machine, guided by an emotional compass that has carried us through centuries of healing.
                </p>
            </section>
            
        </div>
        </main>

    <footer class="bg-gray-900/90 text-center py-6 mt-12 text-gray-400">
        © 2025 Emotion Encoded — All rights reserved.
    </footer>

</body>
</html>
