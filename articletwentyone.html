<!doctype html>

<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Emotion Encoded | Who Do We Trust: Surgeon or Nurse Using AI?</title>
  <style>
    :root{
      --bg:#0b0d10;
      --card:#0f1720;
      --muted:#9aa4b2;
      --accent:#7dd3fc;
      --text:#e6eef6;
      --highlight:#ffd166;
      font-family:Inter, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
    }
    html,body{height:100%;background:var(--bg);color:var(--text);margin:0}
    .container{max-width:880px;margin:40px auto;padding:28px;background:linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01));border-radius:14px;box-shadow:0 10px 30px rgba(2,6,23,0.7)}
    header{display:flex;gap:18px;align-items:center}
    .logo{width:64px;height:64px;border-radius:10px;background:linear-gradient(135deg,var(--accent),#8b5cf6);display:flex;align-items:center;justify-content:center;font-weight:700;color:#061226}
    h1{font-size:1.6rem;margin:0}
    .byline{color:var(--muted);margin-top:6px;font-size:0.95rem}
    .hero{margin:18px 0;border-radius:10px;overflow:hidden}
    .hero img{width:100%;height:auto;display:block}
    article p{line-height:1.7;color:var(--text);margin:14px 0}
    blockquote{background:linear-gradient(90deg, rgba(125,211,252,0.06), rgba(255,209,102,0.04));border-left:4px solid var(--highlight);padding:12px 16px;color:var(--text);margin:16px 0;border-radius:6px}
    .callout{background:rgba(255,255,255,0.02);padding:12px;border-radius:8px;color:var(--muted);font-size:0.95rem}
    .tags{display:flex;flex-wrap:wrap;gap:8px;margin-top:16px}
    .tag{background:rgba(125,211,252,0.08);color:var(--accent);padding:6px 10px;border-radius:999px;font-weight:600;font-size:0.85rem}
    footer{margin-top:24px;border-top:1px solid rgba(255,255,255,0.03);padding-top:16px;display:flex;justify-content:space-between;align-items:center}
    .credits{color:var(--muted);font-size:0.86rem}
    a{color:var(--accent);text-decoration:none}
    pre{background:#071122;padding:12px;border-radius:8px;overflow:auto;color:var(--muted)}
    @media (max-width:600px){.container{margin:18px;padding:18px}h1{font-size:1.25rem}}
  </style>
</head>
<body>
  <div class="container">
    <header>
      <div class="logo">EE</div>
      <div>
        <h1>Who do we trust more When clinicians use AI tools</h1>
        <div class="byline">By Emotion Encoded | Interview and survey analysis • Image credit Nathan Blake</div>
      </div>
    </header><div class="hero">
  <!-- Image used from source cited in credits. Replace src with local file if hosting. -->
  <img src="https://nathanblake.co.uk/wp-content/uploads/2025/06/computational-nurse-feature.jpg" alt="The Computational Nurse" onerror="this.style.display='none'"/>
</div>

<article>
  <p>We asked a simple question: if an AI tool made a clinical suggestion, would you trust a surgeon or a nurse more when they used that tool? Thirty percent of respondents answered that neither professional should be trusted if they are relying solely on AI. The pattern reveals a core tension in public perception. People value professional judgement first and view AI as an auxiliary aid.</p>

  <blockquote>
    "None if I wanted an AI opinion I would go to the AI. When I need a doctor or nurse help I am there for them. If they use the tool without my knowing then that is a different story. The doctor should already have the knowledge to assist." — survey respondent
  </blockquote>

  <p>This result has two immediate implications. First, trust in health professionals does not automatically transfer to trust in the tools they use. Second, transparency matters. Patients want to know when AI is part of the decision process.</p>

  <p>We contrasted clinical trust with opinions about AI in financial roles. When asked whether they would trust an AI fraud detector or an AI loan officer more, responses showed similar caution. People are sceptical about automated decisions that touch on rights and resources, and they expect human oversight.</p>

  <div class="callout">
    Key findings in brief
    <ul>
      <li>Majority of respondents selected none when asked whether they trusted a clinician using AI more than the clinician alone.</li>
      <li>When AI outputs are accompanied by numbers or confident-sounding explanations respondents often express greater confidence, even when those numbers may hide dataset gaps.</li>
      <li>Trust splits by perceived stakes. People tolerate AI in monitoring or administrative roles more than in diagnosis or life critical decisions.</li>
    </ul>
  </div>

  <p>Why does this matter Researchers in psychology point to cognitive biases that explain why people distrust AI or alternatively over-trust it. Algorithm aversion makes professionals wary after a single high-profile mistake. Automation bias means people can over-rely on outputs when they appear precise. The illusion of explainability occurs when simple explanations give a false sense of understanding. These layers combine to shape public perception.</p>

  <p>From a design perspective one practical takeaway is simple: show the limits not only the strengths. Explainable interfaces should include provenance, confidence intervals, and clear caveats about dataset coverage. A tool that displays what it does not know will improve the chance that clinicians will use it appropriately.</p>

  <p>Our survey suggests a policy implication too. If institutions plan to deploy AI at scale they must invest in training, transparency, and liability frameworks. People want both expert judgement and accountable systems. That means clear rules for disclosure, audit trails, and a governance structure that assigns responsibility clearly when errors occur.</p>

  <p>We include this image and cite Nathan Blake for his piece on the computational nurse and how new tools are reshaping clinical workflows. See credit below for the original article.</p>

  <p>Emotion Encoded will continue to study how confidence in AI tools interacts with professional roles. If you are a clinician, legal practitioner or financial manager and you would like to share your perspective please reach out via our website.</p>

</article>

<div class="tags">
  <span class="tag">#EmotionEncoded</span>
  <span class="tag">#AITrust</span>
  <span class="tag">#AIinHealthcare</span>
  <span class="tag">#AutomationBias</span>
  <span class="tag">#AlgorithmAversion</span>
  <span class="tag">#EthicalAI</span>
  <span class="tag">#HumanCenteredAI</span>
</div>

<footer>
  <div class="credits">Image referenced from Nathan Blake. Full reference: Nathan Blake The Computational Nurse, 10 June 2025. https://nathanblake.co.uk/2025/06/10/the-computational-nurse/</div>
  <a href="https://encodedemotion.org" target="_blank" style="color:var(--accent)">Visit Emotion Encoded</a>
</footer>

  </div>
</body>
</html>

