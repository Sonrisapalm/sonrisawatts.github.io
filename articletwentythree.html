<article style="font-family: 'Inter', sans-serif; line-height: 1.7; max-width: 800px; margin: 2rem auto; color: #1a1a1a;">
  <h2>🧩 “Just Because Something Cannot Tell You Everything…”:<br> A Psychologist’s Perspective on AI, Emotion, and the Human Machine</h2>
  <p><strong>By Sonrisa Watts | <a href="https://encodedemotion.org" target="_blank" style="color:#2563eb; text-decoration:none;">Emotion Encoded</a></strong></p>

  <p>When asked whether a single harmful response from an AI therapy app should end its credibility, psychologist <strong>Dr. Jeune</strong> paused, then offered a reflection that captures the tension between progress and precaution in mental health care.</p>

  <blockquote style="border-left: 3px solid #ccc; padding-left: 1rem; color: #444;">
    “Psychological medicine is not comparable to repairing a mechanical engine. Harmful advice can end a life at worst and harm several lives at best.”
  </blockquote>

  <p>Her statement reminds us that therapy is not a mechanical process. It is a living, relational exchange between minds. AI, no matter how advanced, can simulate language but not lived empathy. Still, Dr. Jeune does not dismiss AI outright. She acknowledges a truth that lies at the heart of <em>Emotion Encoded</em>: people in distress will reach for whatever offers relief, and attitudes toward AI vary as widely as the emotions that drive them.</p>

  <blockquote style="border-left: 3px solid #ccc; padding-left: 1rem; color: #444;">
    “Although giving harmful therapeutic advice would lose my confidence,” she explained, “there are many patients who may have a different attitude and worldview that would not be as dismissive as I am.”
  </blockquote>

  <p>This willingness of some to forgive and others to condemn reveals how emotional reasoning shapes trust in technology, not just logic or accuracy.</p>

  <h3>🧠 Professionals as “Human Machines”</h3>
  <p>In response to a question on automation bias—why some professionals follow AI advice even when it contradicts their own judgment—Dr. Jeune described something striking:</p>

  <blockquote style="border-left: 3px solid #ccc; padding-left: 1rem; color: #444;">
    “As human machines, professionals are affected by their mood, emotional availability and knowledge base.”
  </blockquote>

  <p>She recognizes that even experts are not immune to human fluctuation. When working at their minimal standard, professionals may lean on AI out of fatigue or self-doubt. When operating at their maximum standard, they tend to rely on intuition and experience.</p>

  <blockquote style="border-left: 3px solid #ccc; padding-left: 1rem; color: #444;">
    “When a professional is working at their maximum standard, they will trust their judgement over anyone else’s, including AI.”
  </blockquote>

  <p>This distinction captures a core theme of <em>Emotion Encoded</em>: the variable emotional states that influence when and why humans defer to machines.</p>

  <h3>⚖️ Bias, Fairness, and the Question of Data</h3>
  <p>When asked if AI trained on biased human data could ever truly be fair, Dr. Jeune responded with grounded logic:</p>

  <blockquote style="border-left: 3px solid #ccc; padding-left: 1rem; color: #444;">
    “If data is biased, then it cannot be fair, can it?”
  </blockquote>

  <p>Yet she also suggested a practical way forward. Rather than seeing bias as an immovable flaw, she proposed an approach reminiscent of therapeutic pluralism, offering users multiple perspectives and letting them choose what resonates most:</p>

  <blockquote style="border-left: 3px solid #ccc; padding-left: 1rem; color: #444;">
    “There is no practical reason why AI cannot give samples of a range of views and explanations. The help-seeker can opt for an explanation that fits their situation best.”
  </blockquote>

  <p>Her thinking parallels the principle of integrative therapy, where different models are combined to suit each client. It is an invitation for AI to move away from rigidity and toward contextual flexibility.</p>

  <h3>💬 The Illusion of Explainability</h3>
  <p>When asked whether patients would feel reassured by simple AI explanations, even if they were incomplete, Dr. Jeune’s answer was clear:</p>

  <blockquote style="border-left: 3px solid #ccc; padding-left: 1rem; color: #444;">
    “Patients are not homogenous. They all have different attitudes, personalities, moods, intellect, communication styles, reading ability, comprehension ability, infinite differences between patients.”
  </blockquote>

  <p>This insight challenges the illusion that there can ever be one-size-fits-all emotional intelligence in AI. Some users might be satisfied with a quick, soothing answer. Others will crave depth, nuance, and genuine human reflection.</p>

  <h3>❤️ The Human Touch</h3>
  <p>Perhaps the most resonant part of the conversation came when discussing whether AI could replace empathy in therapy.</p>

  <blockquote style="border-left: 3px solid #ccc; padding-left: 1rem; color: #444;">
    “In my opinion, AI cannot replicate the therapeutic encounter. The responses and reactions that pass between a therapist and the help-seeker can be palpable.”
  </blockquote>

  <p>She acknowledges that while virtual or AI-assisted interventions may offer accessibility, they also carry emotional loss—a thinning of presence. Yet she remains measured:</p>

  <blockquote style="border-left: 3px solid #ccc; padding-left: 1rem; color: #444;">
    “Just because something cannot tell you everything does not mean that it cannot tell you anything.”
  </blockquote>

  <p>This line, quietly profound, captures the nuance that defines <em>Emotion Encoded</em>’s mission. AI can inform, guide, and support—but it cannot yet feel. For those who value human connection, it will always fall short. For others, it may be enough.</p>

  <h3>🌐 Reframing AI Through Emotional Perception</h3>
  <p>Dr. Jeune’s reflections reveal not opposition to AI, but emotional realism about it. She neither romanticizes nor rejects it. Her insights illustrate the complexity of trust, shaped by personal worldview, emotional state, and the human desire for reassurance.</p>

  <p>In this way, she redefines the conversation—not <em>Can AI replace us?</em>, but <em>What parts of ourselves do we trust AI with?</em></p>

  <p><strong>Emotion Encoded</strong> continues to collect perspectives like hers from lawyers, doctors, and counselors to uncover how emotional reasoning, bias, and empathy shape humanity’s evolving relationship with intelligent machines.</p>

  <p><em>Because, as Dr. Jeune reminds us, even “human machines” have hearts.</em></p>
</article>

